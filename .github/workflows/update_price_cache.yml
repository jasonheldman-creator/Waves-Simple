name: Update Price Cache

on:
  schedule:
    - cron: "0 2 * * *"
  workflow_dispatch:

permissions:
  contents: write

env:
  MIN_SUCCESS_RATE: "0.90"

jobs:
  update_cache:
    runs-on: ubuntu-latest

    steps:
      - name: Check out repository
        uses: actions/checkout@v3
        with:
          persist-credentials: true

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Pre-build cache inspection
        run: |
          echo "========================================================================"
          echo "PRE-BUILD CACHE INSPECTION"
          echo "========================================================================"
          
          # Check if cache exists
          if [ -f data/cache/prices_cache.parquet ]; then
            echo "✓ Cache file exists"
            CACHE_SIZE=$(stat -c%s data/cache/prices_cache.parquet 2>/dev/null || echo "0")
            echo "  Size: ${CACHE_SIZE} bytes"
            
            # Display existing metadata
            if [ -f data/cache/prices_cache_meta.json ]; then
              echo ""
              echo "Existing Cache Metadata:"
              cat data/cache/prices_cache_meta.json | python3 -m json.tool
            fi
            
            # Extract key info using Python
            echo ""
            python3 << 'EOF'
          import pandas as pd
          import os
          try:
              df = pd.read_parquet('data/cache/prices_cache.parquet')
              print(f"  Symbol count: {len(df.columns)}")
              print(f"  Date range: {df.index.min()} to {df.index.max()}")
              print(f"  Latest date: {df.index.max()}")
          except Exception as e:
              print(f"  Error reading cache: {e}")
          EOF
          else
            echo "✗ Cache file does not exist"
          fi
          echo "========================================================================"

      - name: Build price cache
        env:
          MIN_SUCCESS_RATE: ${{ env.MIN_SUCCESS_RATE }}
        run: |
          echo "=== Building Price Cache ==="
          python build_price_cache.py --force

      - name: Validate cache file and contents
        run: |
          echo "========================================================================"
          echo "POST-BUILD CACHE VALIDATION"
          echo "========================================================================"
          
          # Check cache file existence
          if [ ! -f data/cache/prices_cache.parquet ]; then
            echo "✗ ERROR: Cache file does not exist"
            exit 1
          fi
          
          # Check cache file size
          CACHE_SIZE=$(stat -c%s data/cache/prices_cache.parquet 2>/dev/null || echo "0")
          if [ "$CACHE_SIZE" -eq 0 ]; then
            echo "✗ ERROR: Cache file is empty"
            exit 1
          fi
          
          echo "✓ Cache file exists and is non-empty"
          echo "  Path: data/cache/prices_cache.parquet"
          echo "  Size: ${CACHE_SIZE} bytes"
          
          # Display metadata
          if [ -f data/cache/prices_cache_meta.json ]; then
            echo ""
            echo "Cache Metadata:"
            cat data/cache/prices_cache_meta.json | python3 -m json.tool
            
            # Check for missing required symbols
            if grep -q "missing_required_symbols" data/cache/prices_cache_meta.json; then
              echo ""
              echo "⚠ WARNING: Missing required symbols detected"
              python3 << 'EOF'
          import json
          with open('data/cache/prices_cache_meta.json', 'r') as f:
              meta = json.load(f)
              if 'missing_required_symbols' in meta and meta['missing_required_symbols']:
                  print("Missing symbols by category:")
                  for category, symbols in meta['missing_required_symbols'].items():
                      print(f"  {category}: {symbols}")
          EOF
            fi
          fi
          
          # Detailed cache contents inspection
          echo ""
          echo "Cache Contents Details:"
          python3 << 'EOF'
          import pandas as pd
          import json
          
          try:
              df = pd.read_parquet('data/cache/prices_cache.parquet')
              
              print(f"  Total symbols: {len(df.columns)}")
              print(f"  Total days: {len(df)}")
              print(f"  Date range: {df.index.min()} to {df.index.max()}")
              
              # Check required symbols
              required_volatility = ['^VIX', 'VIXY', 'VXX']
              required_benchmarks = ['SPY', 'QQQ', 'IWM']
              required_cash = ['BIL', 'SHY']
              
              print("")
              print("  Required symbol verification:")
              
              vols_present = [s for s in required_volatility if s in df.columns]
              print(f"    Volatility regime ({len(vols_present)}/{len(required_volatility)}): {vols_present}")
              if not vols_present:
                  print(f"      ✗ MISSING ALL: {required_volatility}")
              
              bench_present = [s for s in required_benchmarks if s in df.columns]
              bench_missing = [s for s in required_benchmarks if s not in df.columns]
              print(f"    Benchmarks ({len(bench_present)}/{len(required_benchmarks)}): {bench_present}")
              if bench_missing:
                  print(f"      ✗ MISSING: {bench_missing}")
              
              cash_present = [s for s in required_cash if s in df.columns]
              cash_missing = [s for s in required_cash if s not in df.columns]
              print(f"    Cash proxies ({len(cash_present)}/{len(required_cash)}): {cash_present}")
              if cash_missing:
                  print(f"      ✗ MISSING: {cash_missing}")
                  
          except Exception as e:
              print(f"  Error inspecting cache: {e}")
          EOF
          
          echo "========================================================================"

      - name: Print operator diagnostics
        run: |
          echo ""
          echo "========================================================================"
          echo "OPERATOR DIAGNOSTICS"
          echo "========================================================================"
          
          python3 << 'EOF'
          import json
          import pandas as pd
          import sys
          
          # Load metadata
          try:
              with open('data/cache/prices_cache_meta.json', 'r') as f:
                  meta = json.load(f)
              
              # Extract key metrics
              spy_last_trading_day = meta.get('last_trading_day', 'N/A')
              cache_max_date = meta.get('max_price_date', 'N/A')
              sessions_behind = meta.get('sessions_behind', 'N/A')
              symbol_count = meta.get('tickers_successful', 0)
              success_rate = meta.get('success_rate', 0.0)
              min_success_rate = meta.get('min_success_rate', 0.9)
              
              # Determine verdict
              has_missing_required = 'missing_required_symbols' in meta and meta['missing_required_symbols']
              meets_threshold = success_rate >= min_success_rate
              is_fresh = sessions_behind == 'N/A' or (isinstance(sessions_behind, int) and sessions_behind <= 1)
              
              verdict = "PASS" if (meets_threshold and not has_missing_required and is_fresh) else "FAIL"
              
              # Print diagnostics
              print(f"SPY_last_trading_day={spy_last_trading_day}")
              print(f"cache_max_date={cache_max_date}")
              print(f"sessions_behind={sessions_behind}")
              print(f"symbol_count={symbol_count}")
              print(f"success_rate={success_rate:.4f}")
              print(f"min_success_rate={min_success_rate:.4f}")
              print(f"CACHE_BUILD_VERDICT={verdict}")
              
              # Exit with failure if verdict is FAIL
              if verdict == "FAIL":
                  print("")
                  print("Build verdict: FAIL")
                  if not meets_threshold:
                      print(f"  - Success rate {success_rate:.2%} below threshold {min_success_rate:.2%}")
                  if has_missing_required:
                      print(f"  - Missing required symbols")
                  if not is_fresh:
                      print(f"  - Cache is {sessions_behind} sessions behind (tolerance: 1)")
                  sys.exit(1)
              else:
                  print("")
                  print("Build verdict: PASS")
                  
          except Exception as e:
              print(f"Error reading metadata: {e}")
              print("CACHE_BUILD_VERDICT=FAIL")
              sys.exit(1)
          EOF
          
          echo "========================================================================"

      - name: Check for changes and determine action
        id: check_changes
        run: |
          echo "========================================================================"
          echo "CHANGE DETECTION AND FRESHNESS CHECK"
          echo "========================================================================"
          
          # Check if there are changes to commit
          git add data/cache/prices_cache.parquet data/cache/prices_cache_meta.json
          
          if git diff --staged --quiet; then
            echo "status=no_changes" >> $GITHUB_OUTPUT
            echo "ℹ No changes detected in cache files"
            
            # Check if cache is fresh or stale
            python3 << 'EOF'
          import json
          import sys
          from datetime import datetime
          
          try:
              with open('data/cache/prices_cache_meta.json', 'r') as f:
                  meta = json.load(f)
              
              max_date_str = meta.get('max_price_date')
              if max_date_str:
                  max_date = datetime.strptime(max_date_str, '%Y-%m-%d')
                  today = datetime.now()
                  days_old = (today - max_date).days
                  
                  print(f"Cache max_date: {max_date_str}")
                  print(f"Days old: {days_old}")
                  
                  if days_old <= 5:
                      print("✓ Cache is fresh (no changes needed)")
                      sys.exit(0)
                  else:
                      print(f"✗ ERROR: Cache is stale ({days_old} days old) AND unchanged")
                      print("This indicates a failure to fetch new data.")
                      sys.exit(1)
              else:
                  print("⚠ WARNING: Unable to determine cache age")
                  sys.exit(0)
          except Exception as e:
              print(f"Error checking cache freshness: {e}")
              sys.exit(0)
          EOF
          else
            echo "status=has_changes" >> $GITHUB_OUTPUT
            echo "✓ Changes detected in cache files"
            
            # Show git diff summary
            echo ""
            echo "Git diff summary:"
            git diff --staged --stat
          fi
          
          echo "========================================================================"

      - name: Commit and push updated cache
        if: steps.check_changes.outputs.status == 'has_changes' && github.ref == 'refs/heads/main' && (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch')
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          git commit -m "Update prices cache (auto)"
          git push
          echo "✓ Cache files committed and pushed"
