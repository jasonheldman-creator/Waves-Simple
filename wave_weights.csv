@st.cache_data
def load_weights(path: str) -> pd.DataFrame:
    """
    Load wave weights from CSV, clean them, and if anything goes wrong,
    fall back to the code-managed DEFAULT_WAVE_WEIGHTS.
    """
    # Helper: default DataFrame built from code
    default_df = pd.DataFrame(DEFAULT_WAVE_WEIGHTS)[["wave", "ticker", "weight"]]

    # Try to read the CSV file safely
    try:
        try:
            # Newer pandas
            raw = pd.read_csv(path, on_bad_lines="skip")
        except TypeError:
            # Older pandas
            raw = pd.read_csv(path, error_bad_lines=False)
    except FileNotFoundError:
        st.warning(
            f"wave_weights.csv not found at '{path}'. "
            "Using code-managed default weights."
        )
        return default_df
    except Exception as e:
        st.warning(
            f"Could not parse wave_weights.csv ({e}). "
            "Using code-managed default weights."
        )
        return default_df

    # If we got nothing usable, fall back
    if raw is None or raw.empty:
        st.warning(
            "wave_weights.csv is empty or malformed. "
            "Using code-managed default weights."
        )
        return default_df

    # ---- Normalize columns (case-insensitive, flexible order) ----
    col_map = {c.strip().lower(): c for c in raw.columns}
    required = ["wave", "ticker", "weight"]
    missing = [r for r in required if r not in col_map]

    if missing:
        st.warning(
            "wave_weights.csv is missing required columns "
            f"{missing}. Using code-managed default weights."
        )
        return default_df

    wave_col = col_map["wave"]
    ticker_col = col_map["ticker"]
    weight_col = col_map["weight"]

    df = raw.copy()

    # ---- Clean up data types / whitespace ----
    df[wave_col] = df[wave_col].astype(str).str.strip()
    df[ticker_col] = df[ticker_col].astype(str).str.strip().str.upper()
    df[weight_col] = pd.to_numeric(df[weight_col], errors="coerce")

    # Drop rows where weight is NaN
    df = df.dropna(subset=[weight_col])

    if df.empty:
        st.warning(
            "No valid weights found in wave_weights.csv "
            "(after cleaning). Using code-managed default weights."
        )
        return default_df

    # ---- Normalize weights to sum to 1.0 within each wave ----
    def _normalize_group(g: pd.DataFrame) -> pd.DataFrame:
        total = g[weight_col].sum()
        if total <= 0:
            # If bad group, just return as-is; it will be dropped later
            return g
        g = g.copy()
        g[weight_col] = g[weight_col] / total
        return g

    df = df.groupby(wave_col, group_keys=False).apply(_normalize_group)

    # Drop any rows where weight is still invalid
    df = df.dropna(subset=[weight_col])
    df = df[df[weight_col] > 0]

    if df.empty:
        st.warning(
            "All rows in wave_weights.csv had invalid or zero weights "
            "after normalization. Using code-managed default weights."
        )
        return default_df

    # ---- Final standardized DataFrame ----
    cleaned = df.rename(
        columns={
            wave_col: "wave",
            ticker_col: "ticker",
            weight_col: "weight",
        }
    )[["wave", "ticker", "weight"]]

    # Try to overwrite a clean version of the CSV for future runs
    try:
        cleaned.to_csv(path, index=False)
    except Exception:
        # Non-fatal: if we can't write, just keep going
        pass

    return cleaned
